{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save filepath \n",
    "home_data_file_path = '/Users/balqeesjabri/Downloads/train.csv'\n",
    "# read the data and store data in DataFrame home_data\n",
    "home_data = pd.read_csv(home_data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "y = home_data.SalePrice\n",
    "X = home_data.drop(['SalePrice'], axis=1)\n",
    "# Divide data into training and validation subsets\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns \n",
    "categorical_cols = [colname for colname in X_train_full.columns if X_train_full[colname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical columns\n",
    "numerical_cols = [colname for colname in X_train_full.columns if X_train_full[colname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#Create transformers for numerical features \n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "   \n",
    "])\n",
    "\n",
    "# Create transformers for categorical features\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to apply different transformers to both feature types  feature types\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# create a pipline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', RandomForestRegressor(n_estimators=250,\n",
    "                                                              random_state=55))\n",
    "                             ])\n",
    "# This line fits the pipeline to the training data,\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Evaluate the model\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, preds))\n",
    "print('rmse:', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data using the preprocessor\n",
    "X_train_preprocessed = preprocessor.transform(X_train)\n",
    "X_valid_preprocessed = preprocessor.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=None)\n",
    "pca.fit(X_train_preprocessed)\n",
    "\n",
    "exp_var = pca.explained_variance_ratio_ * 100\n",
    "cum_exp_var = np.cumsum(exp_var)\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.bar(range(1, 81), exp_var, align='center',\n",
    "        label='Individual explained variance', width=0.5)\n",
    "plt.step(range(1, 81), cum_exp_var, where='mid',\n",
    "         label='Cumulative explained variance', color='red')\n",
    "\n",
    "plt.ylabel('Explained variance percentage')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.xticks(ticks=list(range(1, 81)))\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"cumulative_explained_variance_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=49)\n",
    "X_pca = pd.DataFrame(pca.fit_transform(X_train_preprocessed)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# # the number of folds here is 5\n",
    "\n",
    "# scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "#                               cv=5,\n",
    "#                               scoring='neg_mean_absolute_error')\n",
    "\n",
    "# # Calculate the average cross-validation RMSE score\n",
    "# avg_cross_val_rmse = np.sqrt(np.mean(scores**2))\n",
    "\n",
    "# print(\"RMSE scores:\\n\", avg_cross_val_rmse)\n",
    "# print(\"Average MAE score (across experiments):\")\n",
    "# print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE scores:\n",
      " 29923.87843973819\n",
      "Average MAE score (across experiments):\n",
      "895438500.876228\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# The number of folds here is 5\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the average cross-validation RMSE score\n",
    "avg_cross_val_rmse = np.sqrt(np.mean(scores))\n",
    "\n",
    "print(\"RMSE scores:\\n\", avg_cross_val_rmse)\n",
    "print(\"Average MAE score (across experiments):\")\n",
    "print(scores.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
